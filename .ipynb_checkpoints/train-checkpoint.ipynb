{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from deeplab import DeepLabV3Plus\n",
    "\n",
    "import os\n",
    "\n",
    "from tfrecord_iterator import parse_tfrecords\n",
    "from tfrecord_creator import create_tfrecords\n",
    "from utils import get_miniade20k\n",
    "\n",
    "print('TensorFlow', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path, xml_path, num_classes, dataset_size = get_miniade20k()\n",
    "\n",
    "batch_size = 2\n",
    "H, W = 512, 512\n",
    "\n",
    "tfrecord_dir = os.path.join(os.getcwd(), 'tfrecords')\n",
    "os.makedirs(tfrecord_dir, exist_ok=True)\n",
    "\n",
    "checkpoint_dir = os.path.join(os.getcwd(), 'checkpoints')\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "create_tfrecords(images_path, xml_path, tfrecord_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(image_path, img_height=512, img_width=1024, mask=False, flip=0):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    if not mask:\n",
    "        img = tf.cast(tf.image.decode_png(img, channels=3), dtype=tf.float32)\n",
    "        img = tf.image.resize(images=img, size=[img_height, img_width])\n",
    "        img = tf.image.random_brightness(img, max_delta=50.)\n",
    "        img = tf.image.random_saturation(img, lower=0.5, upper=1.5)\n",
    "        img = tf.image.random_hue(img, max_delta=0.2)\n",
    "        img = tf.image.random_contrast(img, lower=0.5, upper=1.5)\n",
    "        img = tf.clip_by_value(img, 0, 255)\n",
    "        img = tf.case([\n",
    "            (tf.greater(flip , 0), lambda : tf.image.flip_left_right(img))\n",
    "            ], default=lambda : img)\n",
    "        img  = img[:,:,::-1] - tf.constant([103.939, 116.779, 123.68])\n",
    "    else:\n",
    "        img = tf.image.decode_png(img, channels=1)\n",
    "        img = tf.cast(tf.image.resize(images=img, size=[img_height, img_width]), dtype=tf.uint8)\n",
    "        img = tf.case([\n",
    "            (tf.greater(flip , 0), lambda : tf.image.flip_left_right(img))\n",
    "            ], default=lambda : img)\n",
    "    return img\n",
    "\n",
    "def random_crop(image, mask, H=384, W=384):\n",
    "    image_dims = image.shape\n",
    "    offset_h = tf.random.uniform(shape=(1,), maxval=image_dims[0]-H, dtype=tf.int32)[0]\n",
    "    offset_w = tf.random.uniform(shape=(1,), maxval=image_dims[1]-W, dtype=tf.int32)[0]\n",
    "    \n",
    "    image = tf.image.crop_to_bounding_box(image, \n",
    "                                          offset_height=offset_h, \n",
    "                                          offset_width=offset_w, \n",
    "                                          target_height=H, \n",
    "                                          target_width=W)\n",
    "    mask = tf.image.crop_to_bounding_box(mask, \n",
    "                                          offset_height=offset_h, \n",
    "                                          offset_width=offset_w, \n",
    "                                          target_height=H, \n",
    "                                          target_width=W)\n",
    "    return image, mask\n",
    "\n",
    "def load_data(image_path, mask_path, H=384, W=384):\n",
    "    flip = tf.random.uniform(shape=[1, ], minval=0, maxval=2, dtype=tf.int32)[0]\n",
    "    image, mask = get_image(image_path, flip=flip), get_image(mask_path, mask=True, flip=flip)\n",
    "    image, mask = random_crop(image, mask, H=H, W=W)\n",
    "    mask = tf.one_hot(tf.squeeze(mask), depth=num_classes)\n",
    "    return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((image_list, \n",
    "                                                    mask_list))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=128)\n",
    "train_dataset = train_dataset.apply(\n",
    "    tf.data.experimental.map_and_batch(map_func=load_data, \n",
    "                                       batch_size=batch_size, \n",
    "                                       num_parallel_calls=tf.data.experimental.AUTOTUNE, \n",
    "                                       drop_remainder=True))\n",
    "train_dataset = train_dataset.repeat()\n",
    "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "print(train_dataset)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_image_list, \n",
    "                                                  val_mask_list))\n",
    "val_dataset = val_dataset.apply(\n",
    "    tf.data.experimental.map_and_batch(map_func=load_data, \n",
    "                                       batch_size=batch_size, \n",
    "                                       num_parallel_calls=tf.data.experimental.AUTOTUNE, \n",
    "                                       drop_remainder=True))\n",
    "val_dataset = val_dataset.repeat()\n",
    "val_dataset = val_dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "with strategy.scope():\n",
    "    model = DeepLabV3Plus(H, W, num_classes)\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "            layer.momentum = 0.9997\n",
    "        elif isinstance(layer, tf.keras.layers.Conv2D):\n",
    "            layer.kernel_regularizer = tf.keras.regularizers.l2(1e-4)\n",
    "    model.compile(loss=loss, \n",
    "                  optimizer=tf.optimizers.Adam(learning_rate=5e-4), \n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = TensorBoard(log_dir='logs', write_graph=True, update_freq='batch')\n",
    "mc = ModelCheckpoint(mode='min', filepath='top_weights.h5',\n",
    "                     monitor='val_loss',\n",
    "                     save_best_only='True',\n",
    "                     save_weights_only='True', verbose=1)\n",
    "callbacks = [mc, tb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_dataset,\n",
    "          steps_per_epoch=len(image_list)//batch_size,\n",
    "          epochs=100,\n",
    "          validation_data=val_dataset,\n",
    "          validation_steps=len(val_image_list)//batch_size, \n",
    "          callbacks=callbacks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
